/**
 * h2AåŒé‡ç¼“å†²å¼‚æ­¥æ¶ˆæ¯é˜Ÿåˆ—æ€§èƒ½åŸºå‡†æµ‹è¯•
 * 
 * éªŒè¯ç³»ç»Ÿæ˜¯å¦æ»¡è¶³æ€§èƒ½è¦æ±‚ï¼š
 * - ç¼“å†²åŒºåˆ‡æ¢å»¶è¿Ÿ < 1ms
 * - æ¶ˆæ¯ååé‡ > 10,000 msgs/sec
 * - å†…å­˜ä½¿ç”¨ < 100MB for 1M messages
 * - é›¶æ¶ˆæ¯ä¸¢å¤±ä¿è¯
 */

import { performance } from 'perf_hooks';
import {
  h2AAsyncMessageQueue,
  createHighPerformanceQueue
} from '../../src/core/message-queue.js';
import {
  BackpressureStrategy,
  QueueMetrics,
  QueuePerformanceMetrics
} from '../../src/types/message-queue.js';

// ============================================================================
// åŸºå‡†æµ‹è¯•è¾…åŠ©å·¥å…·
// ============================================================================

/**
 * å»¶è¿Ÿå·¥å…·å‡½æ•°
 */
const delay = (ms: number): Promise<void> => 
  new Promise(resolve => setTimeout(resolve, ms));

/**
 * å†…å­˜ä½¿ç”¨ç›‘æ§
 */
function getMemoryUsage(): NodeJS.MemoryUsage {
  return process.memoryUsage();
}

/**
 * æ ¼å¼åŒ–å†…å­˜ä½¿ç”¨é‡
 */
function formatMemory(bytes: number): string {
  const mb = bytes / (1024 * 1024);
  return `${mb.toFixed(2)} MB`;
}

/**
 * åŸºå‡†æµ‹è¯•ç»“æœæ¥å£
 */
interface BenchmarkResult {
  testName: string;
  duration: number;
  throughput: number;
  avgLatency: number;
  maxLatency: number;
  minLatency: number;
  memoryUsage: {
    start: NodeJS.MemoryUsage;
    peak: NodeJS.MemoryUsage;
    end: NodeJS.MemoryUsage;
  };
  messagesProcessed: number;
  errors: number;
  success: boolean;
}

/**
 * æµ‹è¯•æ¶ˆæ¯ç±»å‹
 */
interface BenchmarkMessage {
  id: number;
  timestamp: number;
  payload: string;
  sequence: number;
}

/**
 * åˆ›å»ºåŸºå‡†æµ‹è¯•æ¶ˆæ¯
 */
function createBenchmarkMessage(id: number, sequence: number, payloadSize: number = 64): BenchmarkMessage {
  return {
    id,
    timestamp: performance.now(),
    payload: 'x'.repeat(payloadSize),
    sequence
  };
}

/**
 * åŸºå‡†æµ‹è¯•è¿è¡Œå™¨
 */
class BenchmarkRunner {
  private results: BenchmarkResult[] = [];

  async runBenchmark(
    testName: string,
    testFunction: () => Promise<BenchmarkResult>
  ): Promise<BenchmarkResult> {
    console.log(`\nğŸš€ Running benchmark: ${testName}`);
    console.log('=' .repeat(60));

    // é¢„çƒ­GC
    if (global.gc) {
      global.gc();
    }

    const startMemory = getMemoryUsage();
    const startTime = performance.now();

    try {
      const result = await testFunction();
      result.testName = testName;
      
      this.results.push(result);
      this.printResult(result);
      
      return result;
    } catch (error) {
      console.error(`âŒ Benchmark failed: ${error}`);
      throw error;
    } finally {
      // æ¸…ç†
      if (global.gc) {
        global.gc();
      }
    }
  }

  private printResult(result: BenchmarkResult): void {
    console.log(`âœ… Test: ${result.testName}`);
    console.log(`   Duration: ${result.duration.toFixed(2)} ms`);
    console.log(`   Throughput: ${result.throughput.toFixed(2)} msgs/sec`);
    console.log(`   Avg Latency: ${result.avgLatency.toFixed(3)} ms`);
    console.log(`   Max Latency: ${result.maxLatency.toFixed(3)} ms`);
    console.log(`   Min Latency: ${result.minLatency.toFixed(3)} ms`);
    console.log(`   Messages: ${result.messagesProcessed.toLocaleString()}`);
    console.log(`   Errors: ${result.errors}`);
    console.log(`   Memory Start: ${formatMemory(result.memoryUsage.start.heapUsed)}`);
    console.log(`   Memory Peak: ${formatMemory(result.memoryUsage.peak.heapUsed)}`);
    console.log(`   Memory End: ${formatMemory(result.memoryUsage.end.heapUsed)}`);
    console.log(`   Success: ${result.success ? 'âœ…' : 'âŒ'}`);
  }

  getAllResults(): BenchmarkResult[] {
    return [...this.results];
  }

  printSummary(): void {
    console.log('\nğŸ“Š BENCHMARK SUMMARY');
    console.log('=' .repeat(60));
    
    const successful = this.results.filter(r => r.success);
    const failed = this.results.filter(r => !r.success);
    
    console.log(`Total Tests: ${this.results.length}`);
    console.log(`Successful: ${successful.length}`);
    console.log(`Failed: ${failed.length}`);
    
    if (successful.length > 0) {
      const avgThroughput = successful.reduce((sum, r) => sum + r.throughput, 0) / successful.length;
      const avgLatency = successful.reduce((sum, r) => sum + r.avgLatency, 0) / successful.length;
      const maxThroughput = Math.max(...successful.map(r => r.throughput));
      const minLatency = Math.min(...successful.map(r => r.avgLatency));
      
      console.log(`\nğŸ“ˆ Performance Metrics:`);
      console.log(`   Average Throughput: ${avgThroughput.toFixed(2)} msgs/sec`);
      console.log(`   Maximum Throughput: ${maxThroughput.toFixed(2)} msgs/sec`);
      console.log(`   Average Latency: ${avgLatency.toFixed(3)} ms`);
      console.log(`   Minimum Latency: ${minLatency.toFixed(3)} ms`);
      
      // æ€§èƒ½è¦æ±‚éªŒè¯
      console.log(`\nâœ¨ Performance Requirements:`);
      console.log(`   Throughput > 10,000 msgs/sec: ${maxThroughput > 10000 ? 'âœ…' : 'âŒ'}`);
      console.log(`   Latency < 1ms: ${minLatency < 1 ? 'âœ…' : 'âŒ'}`);
    }
  }
}

// ============================================================================
// åŸºå‡†æµ‹è¯•å¥—ä»¶
// ============================================================================

/**
 * åŸºç¡€ååé‡æµ‹è¯•
 */
async function benchmarkBasicThroughput(): Promise<BenchmarkResult> {
  const messageCount = 50000;
  const queue = createHighPerformanceQueue<BenchmarkMessage>();
  
  const startMemory = getMemoryUsage();
  let peakMemory = startMemory;
  
  const latencies: number[] = [];
  let errors = 0;
  
  const startTime = performance.now();
  const iterator = queue[Symbol.asyncIterator]();
  
  // ç”Ÿäº§è€…ï¼šå¿«é€Ÿå…¥é˜Ÿ
  const producer = async () => {
    for (let i = 0; i < messageCount; i++) {
      try {
        const message = createBenchmarkMessage(i + 1, i + 1);
        queue.enqueue(message);
        
        // ç›‘æ§å†…å­˜ä½¿ç”¨
        const currentMemory = getMemoryUsage();
        if (currentMemory.heapUsed > peakMemory.heapUsed) {
          peakMemory = currentMemory;
        }
      } catch (error) {
        errors++;
      }
    }
    queue.done();
  };
  
  // æ¶ˆè´¹è€…ï¼šå¤„ç†æ‰€æœ‰æ¶ˆæ¯
  const consumer = async () => {
    let processed = 0;
    for await (const message of queue) {
      const latency = performance.now() - message.timestamp;
      latencies.push(latency);
      processed++;
    }
    return processed;
  };
  
  // å¹¶è¡Œè¿è¡Œ
  const [, messagesProcessed] = await Promise.all([
    producer(),
    consumer()
  ]);
  
  const endTime = performance.now();
  const endMemory = getMemoryUsage();
  const duration = endTime - startTime;
  
  const avgLatency = latencies.length > 0 ? latencies.reduce((a, b) => a + b) / latencies.length : 0;
  const maxLatency = latencies.length > 0 ? Math.max(...latencies) : 0;
  const minLatency = latencies.length > 0 ? Math.min(...latencies) : 0;
  const throughput = messagesProcessed / (duration / 1000);
  
  queue.dispose();
  
  return {
    testName: 'Basic Throughput',
    duration,
    throughput,
    avgLatency,
    maxLatency,
    minLatency,
    memoryUsage: {
      start: startMemory,
      peak: peakMemory,
      end: endMemory
    },
    messagesProcessed,
    errors,
    success: messagesProcessed === messageCount && errors === 0
  };
}

/**
 * é›¶å»¶è¿Ÿè·¯å¾„æµ‹è¯•ï¼ˆç›´æ¥ä¼ é€’ï¼‰
 */
async function benchmarkZeroLatencyPath(): Promise<BenchmarkResult> {
  const messageCount = 10000;
  const queue = new h2AAsyncMessageQueue<BenchmarkMessage>({
    enableMetrics: true,
    maxBufferSize: 1 // å°ç¼“å†²åŒºå¼ºåˆ¶ä½¿ç”¨é›¶å»¶è¿Ÿè·¯å¾„
  });
  
  const startMemory = getMemoryUsage();
  let peakMemory = startMemory;
  
  const latencies: number[] = [];
  let errors = 0;
  
  const startTime = performance.now();
  const iterator = queue[Symbol.asyncIterator]();
  
  let processed = 0;
  
  // äº¤æ›¿ç”Ÿäº§å’Œæ¶ˆè´¹ï¼Œæµ‹è¯•é›¶å»¶è¿Ÿè·¯å¾„
  for (let i = 0; i < messageCount; i++) {
    try {
      const message = createBenchmarkMessage(i + 1, i + 1);
      
      // å¯åŠ¨è¯»å–Promise
      const readPromise = iterator.next();
      
      // ç«‹å³å…¥é˜Ÿæ¶ˆæ¯ï¼ˆåº”è¯¥ç›´æ¥ä¼ é€’ç»™ç­‰å¾…çš„è¯»å–è€…ï¼‰
      queue.enqueue(message);
      
      // ç­‰å¾…æ¶ˆæ¯è¢«è¯»å–
      const result = await readPromise;
      
      if (!result.done) {
        const latency = performance.now() - result.value.timestamp;
        latencies.push(latency);
        processed++;
      }
      
      // ç›‘æ§å†…å­˜ä½¿ç”¨
      const currentMemory = getMemoryUsage();
      if (currentMemory.heapUsed > peakMemory.heapUsed) {
        peakMemory = currentMemory;
      }
    } catch (error) {
      errors++;
    }
  }
  
  const endTime = performance.now();
  const endMemory = getMemoryUsage();
  const duration = endTime - startTime;
  
  const avgLatency = latencies.length > 0 ? latencies.reduce((a, b) => a + b) / latencies.length : 0;
  const maxLatency = latencies.length > 0 ? Math.max(...latencies) : 0;
  const minLatency = latencies.length > 0 ? Math.min(...latencies) : 0;
  const throughput = processed / (duration / 1000);
  
  queue.dispose();
  
  return {
    testName: 'Zero Latency Path',
    duration,
    throughput,
    avgLatency,
    maxLatency,
    minLatency,
    memoryUsage: {
      start: startMemory,
      peak: peakMemory,
      end: endMemory
    },
    messagesProcessed: processed,
    errors,
    success: processed === messageCount && errors === 0 && avgLatency < 1
  };
}

/**
 * å¤§å®¹é‡å†…å­˜æµ‹è¯•
 */
async function benchmarkLargeCapacity(): Promise<BenchmarkResult> {
  const messageCount = 100000; // 10ä¸‡æ¶ˆæ¯
  const queue = new h2AAsyncMessageQueue<BenchmarkMessage>({
    enableMetrics: true,
    maxBufferSize: messageCount,
    backpressureStrategy: BackpressureStrategy.ERROR
  });
  
  const startMemory = getMemoryUsage();
  let peakMemory = startMemory;
  
  const latencies: number[] = [];
  let errors = 0;
  
  const startTime = performance.now();
  
  // é˜¶æ®µ1ï¼šå¿«é€Ÿå¡«å……é˜Ÿåˆ—
  console.log('   Phase 1: Filling queue...');
  for (let i = 0; i < messageCount; i++) {
    try {
      const message = createBenchmarkMessage(i + 1, i + 1, 128); // ç¨å¤§çš„æ¶ˆæ¯
      queue.enqueue(message);
      
      // æ¯1000ä¸ªæ¶ˆæ¯æ£€æŸ¥ä¸€æ¬¡å†…å­˜
      if (i % 1000 === 0) {
        const currentMemory = getMemoryUsage();
        if (currentMemory.heapUsed > peakMemory.heapUsed) {
          peakMemory = currentMemory;
        }
      }
    } catch (error) {
      errors++;
    }
  }
  
  const fillTime = performance.now();
  console.log(`   Fill completed in ${(fillTime - startTime).toFixed(2)} ms`);
  
  // é˜¶æ®µ2ï¼šå¿«é€Ÿæ¸…ç©ºé˜Ÿåˆ—
  console.log('   Phase 2: Draining queue...');
  const iterator = queue[Symbol.asyncIterator]();
  queue.done();
  
  let processed = 0;
  for await (const message of queue) {
    const latency = performance.now() - message.timestamp;
    latencies.push(latency);
    processed++;
    
    // æ¯1000ä¸ªæ¶ˆæ¯æ£€æŸ¥ä¸€æ¬¡å†…å­˜
    if (processed % 1000 === 0) {
      const currentMemory = getMemoryUsage();
      if (currentMemory.heapUsed > peakMemory.heapUsed) {
        peakMemory = currentMemory;
      }
    }
  }
  
  const endTime = performance.now();
  const endMemory = getMemoryUsage();
  const duration = endTime - startTime;
  
  const avgLatency = latencies.length > 0 ? latencies.reduce((a, b) => a + b) / latencies.length : 0;
  const maxLatency = latencies.length > 0 ? Math.max(...latencies) : 0;
  const minLatency = latencies.length > 0 ? Math.min(...latencies) : 0;
  const throughput = processed / (duration / 1000);
  
  // å†…å­˜ä½¿ç”¨éªŒè¯ï¼ˆ100MBé™åˆ¶ï¼‰
  const peakMemoryMB = peakMemory.heapUsed / (1024 * 1024);
  const memoryEfficient = peakMemoryMB < 100;
  
  queue.dispose();
  
  return {
    testName: 'Large Capacity',
    duration,
    throughput,
    avgLatency,
    maxLatency,
    minLatency,
    memoryUsage: {
      start: startMemory,
      peak: peakMemory,
      end: endMemory
    },
    messagesProcessed: processed,
    errors,
    success: processed === messageCount && errors === 0 && memoryEfficient
  };
}

/**
 * èƒŒå‹æ§åˆ¶æ€§èƒ½æµ‹è¯•
 */
async function benchmarkBackpressurePerformance(): Promise<BenchmarkResult> {
  const messageCount = 20000;
  const bufferSize = 100;
  const queue = new h2AAsyncMessageQueue<BenchmarkMessage>({
    enableMetrics: true,
    maxBufferSize: bufferSize,
    backpressureStrategy: BackpressureStrategy.DROP_OLDEST
  });
  
  const startMemory = getMemoryUsage();
  let peakMemory = startMemory;
  
  const latencies: number[] = [];
  let errors = 0;
  
  const startTime = performance.now();
  const iterator = queue[Symbol.asyncIterator]();
  
  // ç”Ÿäº§è€…ï¼šå¿«é€Ÿç”Ÿäº§è¶…å‡ºç¼“å†²åŒºå®¹é‡çš„æ¶ˆæ¯
  const producer = async () => {
    for (let i = 0; i < messageCount; i++) {
      try {
        const message = createBenchmarkMessage(i + 1, i + 1);
        queue.enqueue(message);
        
        // å°å»¶è¿Ÿæ¨¡æ‹Ÿç”Ÿäº§å‹åŠ›
        if (i % 100 === 0) {
          await delay(1);
        }
      } catch (error) {
        errors++;
      }
    }
    queue.done();
  };
  
  // æ¶ˆè´¹è€…ï¼šé€‚ä¸­é€Ÿåº¦æ¶ˆè´¹
  const consumer = async () => {
    let processed = 0;
    for await (const message of queue) {
      const latency = performance.now() - message.timestamp;
      latencies.push(latency);
      processed++;
      
      // æ¨¡æ‹Ÿå¤„ç†æ—¶é—´
      if (processed % 50 === 0) {
        await delay(1);
        
        const currentMemory = getMemoryUsage();
        if (currentMemory.heapUsed > peakMemory.heapUsed) {
          peakMemory = currentMemory;
        }
      }
    }
    return processed;
  };
  
  // å¹¶è¡Œè¿è¡Œ
  const [, messagesProcessed] = await Promise.all([
    producer(),
    consumer()
  ]);
  
  const endTime = performance.now();
  const endMemory = getMemoryUsage();
  const duration = endTime - startTime;
  
  const avgLatency = latencies.length > 0 ? latencies.reduce((a, b) => a + b) / latencies.length : 0;
  const maxLatency = latencies.length > 0 ? Math.max(...latencies) : 0;
  const minLatency = latencies.length > 0 ? Math.min(...latencies) : 0;
  const throughput = messagesProcessed / (duration / 1000);
  
  // è·å–é˜Ÿåˆ—æŒ‡æ ‡
  const metrics = queue.getMetrics();
  console.log(`   Dropped messages: ${metrics.droppedMessages}`);
  
  queue.dispose();
  
  return {
    testName: 'Backpressure Performance',
    duration,
    throughput,
    avgLatency,
    maxLatency,
    minLatency,
    memoryUsage: {
      start: startMemory,
      peak: peakMemory,
      end: endMemory
    },
    messagesProcessed,
    errors,
    success: messagesProcessed > 0 && errors === 0 && throughput > 1000
  };
}

/**
 * å¹¶å‘å‹åŠ›æµ‹è¯•
 */
async function benchmarkConcurrentStress(): Promise<BenchmarkResult> {
  const producerCount = 5;
  const messagesPerProducer = 5000;
  const totalMessages = producerCount * messagesPerProducer;
  
  const queue = createHighPerformanceQueue<BenchmarkMessage>();
  
  const startMemory = getMemoryUsage();
  let peakMemory = startMemory;
  
  const latencies: number[] = [];
  let errors = 0;
  
  const startTime = performance.now();
  const iterator = queue[Symbol.asyncIterator]();
  
  // å¤šä¸ªå¹¶å‘ç”Ÿäº§è€…
  const producers = Array.from({ length: producerCount }, (_, producerId) =>
    async () => {
      for (let i = 0; i < messagesPerProducer; i++) {
        try {
          const messageId = producerId * messagesPerProducer + i + 1;
          const message = createBenchmarkMessage(messageId, messageId);
          queue.enqueue(message);
          
          // éšæœºå°å»¶è¿Ÿå¢åŠ å¹¶å‘å¤æ‚æ€§
          if (Math.random() < 0.01) {
            await delay(1);
          }
        } catch (error) {
          errors++;
        }
      }
    }
  );
  
  // æ¶ˆè´¹è€…
  const consumer = async () => {
    let processed = 0;
    for await (const message of queue) {
      const latency = performance.now() - message.timestamp;
      latencies.push(latency);
      processed++;
      
      // å®šæœŸæ£€æŸ¥å†…å­˜
      if (processed % 1000 === 0) {
        const currentMemory = getMemoryUsage();
        if (currentMemory.heapUsed > peakMemory.heapUsed) {
          peakMemory = currentMemory;
        }
      }
    }
    return processed;
  };
  
  // å¯åŠ¨æ¶ˆè´¹è€…
  const consumerPromise = consumer();
  
  // è¿è¡Œæ‰€æœ‰ç”Ÿäº§è€…
  await Promise.all(producers.map(p => p()));
  queue.done();
  
  // ç­‰å¾…æ¶ˆè´¹è€…å®Œæˆ
  const messagesProcessed = await consumerPromise;
  
  const endTime = performance.now();
  const endMemory = getMemoryUsage();
  const duration = endTime - startTime;
  
  const avgLatency = latencies.length > 0 ? latencies.reduce((a, b) => a + b) / latencies.length : 0;
  const maxLatency = latencies.length > 0 ? Math.max(...latencies) : 0;
  const minLatency = latencies.length > 0 ? Math.min(...latencies) : 0;
  const throughput = messagesProcessed / (duration / 1000);
  
  queue.dispose();
  
  return {
    testName: 'Concurrent Stress',
    duration,
    throughput,
    avgLatency,
    maxLatency,
    minLatency,
    memoryUsage: {
      start: startMemory,
      peak: peakMemory,
      end: endMemory
    },
    messagesProcessed,
    errors,
    success: messagesProcessed >= totalMessages * 0.99 && errors < totalMessages * 0.01 && throughput > 5000
  };
}

// ============================================================================
// ä¸»åŸºå‡†æµ‹è¯•æ‰§è¡Œ
// ============================================================================

/**
 * è¿è¡Œæ‰€æœ‰åŸºå‡†æµ‹è¯•
 */
export async function runAllBenchmarks(): Promise<BenchmarkResult[]> {
  const runner = new BenchmarkRunner();
  
  console.log('ğŸ”¥ h2AåŒé‡ç¼“å†²å¼‚æ­¥æ¶ˆæ¯é˜Ÿåˆ—æ€§èƒ½åŸºå‡†æµ‹è¯•');
  console.log('=' .repeat(60));
  console.log('éªŒè¯æ€§èƒ½è¦æ±‚ï¼š');
  console.log('â€¢ ç¼“å†²åŒºåˆ‡æ¢å»¶è¿Ÿ < 1ms');
  console.log('â€¢ æ¶ˆæ¯ååé‡ > 10,000 msgs/sec');
  console.log('â€¢ å†…å­˜ä½¿ç”¨ < 100MB for å¤§å®¹é‡æ¶ˆæ¯');
  console.log('â€¢ é›¶æ¶ˆæ¯ä¸¢å¤±ä¿è¯');
  
  const results: BenchmarkResult[] = [];
  
  try {
    // 1. åŸºç¡€ååé‡æµ‹è¯•
    results.push(await runner.runBenchmark(
      'Basic Throughput Test',
      benchmarkBasicThroughput
    ));
    
    // 2. é›¶å»¶è¿Ÿè·¯å¾„æµ‹è¯•
    results.push(await runner.runBenchmark(
      'Zero Latency Path Test',
      benchmarkZeroLatencyPath
    ));
    
    // 3. å¤§å®¹é‡å†…å­˜æµ‹è¯•
    results.push(await runner.runBenchmark(
      'Large Capacity Memory Test',
      benchmarkLargeCapacity
    ));
    
    // 4. èƒŒå‹æ§åˆ¶æ€§èƒ½æµ‹è¯•
    results.push(await runner.runBenchmark(
      'Backpressure Performance Test',
      benchmarkBackpressurePerformance
    ));
    
    // 5. å¹¶å‘å‹åŠ›æµ‹è¯•
    results.push(await runner.runBenchmark(
      'Concurrent Stress Test',
      benchmarkConcurrentStress
    ));
    
  } catch (error) {
    console.error('âŒ Benchmark suite failed:', error);
  } finally {
    // æ‰“å°æ€»ç»“
    runner.printSummary();
  }
  
  return results;
}

/**
 * éªŒè¯æ€§èƒ½è¦æ±‚
 */
export function validatePerformanceRequirements(results: BenchmarkResult[]): boolean {
  const successful = results.filter(r => r.success);
  
  if (successful.length === 0) {
    console.log('âŒ No successful benchmarks to validate');
    return false;
  }
  
  // æ£€æŸ¥ååé‡è¦æ±‚
  const maxThroughput = Math.max(...successful.map(r => r.throughput));
  const throughputOk = maxThroughput > 10000;
  
  // æ£€æŸ¥å»¶è¿Ÿè¦æ±‚
  const minAvgLatency = Math.min(...successful.map(r => r.avgLatency));
  const latencyOk = minAvgLatency < 1;
  
  // æ£€æŸ¥å†…å­˜è¦æ±‚ï¼ˆé’ˆå¯¹å¤§å®¹é‡æµ‹è¯•ï¼‰
  const largeCapacityTest = successful.find(r => r.testName.includes('Large Capacity'));
  const memoryOk = largeCapacityTest ? 
    (largeCapacityTest.memoryUsage.peak.heapUsed / (1024 * 1024)) < 100 : 
    true;
  
  console.log('\nğŸ¯ PERFORMANCE REQUIREMENTS VALIDATION');
  console.log('=' .repeat(60));
  console.log(`âœ¨ Throughput > 10,000 msgs/sec: ${throughputOk ? 'âœ…' : 'âŒ'} (${maxThroughput.toFixed(2)} msgs/sec)`);
  console.log(`âœ¨ Latency < 1ms: ${latencyOk ? 'âœ…' : 'âŒ'} (${minAvgLatency.toFixed(3)} ms)`);
  console.log(`âœ¨ Memory < 100MB: ${memoryOk ? 'âœ…' : 'âŒ'} ${largeCapacityTest ? `(${(largeCapacityTest.memoryUsage.peak.heapUsed / (1024 * 1024)).toFixed(2)} MB)` : '(N/A)'}`);
  
  const allRequirementsMet = throughputOk && latencyOk && memoryOk;
  console.log(`\nğŸ† Overall: ${allRequirementsMet ? 'âœ… ALL REQUIREMENTS MET' : 'âŒ REQUIREMENTS NOT MET'}`);
  
  return allRequirementsMet;
}

// ============================================================================
// ç‹¬ç«‹è¿è¡Œè„šæœ¬
// ============================================================================

if (require.main === module) {
  (async () => {
    try {
      const results = await runAllBenchmarks();
      const requirementsMet = validatePerformanceRequirements(results);
      
      process.exit(requirementsMet ? 0 : 1);
    } catch (error) {
      console.error('Benchmark execution failed:', error);
      process.exit(1);
    }
  })();
}